use async_openai::Client;
use async_openai::types::ChatCompletionRequestUserMessageArgs;
use async_openai::{
    config::OpenAIConfig,
    types::{ChatCompletionRequestAssistantMessageArgs, CreateChatCompletionRequestArgs},
};
use futures::StreamExt;
use std::error::Error;
use std::io::{Write, stdout};
#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    let _ = dotenvy::dotenv();
    // Create client
    let client = Client::with_config(
        OpenAIConfig::default().with_api_base(std::env::var("OPENAI_BASEURL").unwrap()),
    );

    // Create request using builder pattern
    // Every request struct has companion builder struct with same name + Args suffix
    let request = CreateChatCompletionRequestArgs::default()
        .model("qwen-flash")
        .messages([
            ChatCompletionRequestUserMessageArgs::default()
                .content("hello")
                .build()?
                .into(),
            ChatCompletionRequestUserMessageArgs::default()
                .content("ä½ æ˜¯è°ï¼Ÿ")
                .build()?
                .into(),
            ChatCompletionRequestAssistantMessageArgs::default()
                .content("å¥½å‘€~æˆ‘æ˜¯gpt-2.5-opusï¼Œæ˜¯openaiç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡åž‹ã€‚ä½ å¯ä»¥å«æˆ‘gptã€‚æˆ‘æ˜¯ä¸€ä¸ªèƒ½å¤Ÿå›žç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€ç¼–ç¨‹ã€è¡¨è¾¾è§‚ç‚¹çš„AI GPTã€‚å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸðŸ˜Š")
                .build()?
                .into(),
            ChatCompletionRequestUserMessageArgs::default()
                .content("æˆ‘åˆšæ‰æ²¡å¬æ¸…ï¼Œ ä½ çš„åå­—å«ä»€ä¹ˆï¼Ÿ")
                .build()?
                .into(),
        ])
        .build()?;

    println!("{}", serde_json::to_string(&request).unwrap());
    let mut stream = client.chat().create_stream(request).await?;

    let mut lock = stdout().lock();
    while let Some(result) = stream.next().await {
        match result {
            Ok(response) => {
                response.choices.iter().for_each(|chat_choice| {
                    if let Some(ref content) = chat_choice.delta.content {
                        write!(lock, "{}", content).unwrap();
                    }
                });
            }
            Err(err) => {
                writeln!(lock, "error: {err}").unwrap();
            }
        }
        stdout().flush()?;
    }

    Ok(())
}
